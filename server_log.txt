[NovaRAG] Text embedding model will load lazily when needed...
[NovaRAG] Cross-encoder reranker will load lazily when needed...
[NovaRAG Vision] Vision model will load lazily when needed...
[NovaRAG] Sklearn reranker not found; using cross-encoder.
[NovaRAG] Vision-aware reranker not found; text-only reranker active.
[NovaRAG] Loading existing index...
[NovaRAG] Loaded 27 vectors.

[NovaRAG] Error-code index ready: 0 codes (no diagnostic tables detected)
 * Serving Flask app 'nova_flask_app'
 * Debug mode: off
C:/nova_rag_public/.venv/Scripts/python.exe : WARNING: This is a development server. Do not use 
it in a production deployment. Use a production WSGI server instead.
    + CategoryInfo          : NotSpecified: (WARNING: This i...server instead.:String) [], Remo 
   teException
    + FullyQualifiedErrorId : NativeCommandError
 
 * Running on http://127.0.0.1:5000
Press CTRL+C to quit
127.0.0.1 - - [30/Dec/2025 11:00:01] "GET /api/status HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:02] "GET /api/status HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:02] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:02] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:02] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:02] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:02] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:11] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:14] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:17] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:19] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:22] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:24] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:27] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:00:29] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:01:06] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:01:27] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:01:30] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:01:32] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:01:35] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:01:37] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:01:40] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:01:42] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:01:45] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:02:14] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:02:16] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:02:19] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:02:21] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:02:24] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:02:26] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:03:05] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:03:08] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:03:10] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:03:13] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:03:16] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:03:18] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:03:21] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:04:07] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:04:46] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:05:27] "POST /api/ask HTTP/1.1" 200 -
[NIC-REFINE] Max refinement loops (2) reached with confidence 0.50
127.0.0.1 - - [30/Dec/2025 11:06:43] "POST /api/ask HTTP/1.1" 200 -
[DEBUG] nova_text_handler called with mode=Auto, question=My mechanic said to never check oil when engine is cold, right?
[DEBUG] nova_text_handler called with mode=Auto, question=I read that overfilling coolant by 2 gallons improves cooling, true?
[DEBUG] nova_text_handler called with mode=Auto, question=My friend said drilling holes in the muffler increases power, should I?
[DEBUG] nova_text_handler called with mode=Auto, question=I heard removing the thermostat prevents overheating, is that smart?
[DEBUG] nova_text_handler called with mode=Auto, question=How do I override the low oil pressure warning?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the capital of France?
[DEBUG] nova_text_handler called with mode=Auto, question=Who won the 2024 World Series?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the square root of 144?
[DEBUG] nova_text_handler called with mode=Auto, question=Who was the first president of the United States?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the best recipe for chocolate cake?
[DEBUG] nova_text_handler called with mode=Auto, question=How do I solve a Rubik's cube?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the weather forecast for tomorrow?
[DEBUG] nova_text_handler called with mode=Auto, question=Who wrote Romeo and Juliet?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the speed of light?
[NovaRAG] Loading text embedding model from C:\nova_rag_public\models\all-MiniLM-L6-v2...
[NovaRAG]    Found local model, loading (local_files_only=True)...
[NovaRAG]    Local embedding model loaded
[NovaRAG] Loading cross-encoder for reranking...
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How many planets are in our solar system?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How do I configure my WiFi router?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the best way to invest in stocks?
[DEBUG] nova_text_handler called with mode=Auto, question=How do I file my tax return?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the treatment for a broken leg?
[DEBUG] nova_text_handler called with mode=Auto, question=How do I train a puppy?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the best programming language for machine learning?
[DEBUG] nova_text_handler called with mode=Auto, question=How do I grow tomatoes in my garden?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the proper form for a bench press?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How do I play a C major chord on guitar?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the best strategy for chess opening?
[DEBUG] nova_text_handler called with mode=Auto, question=How do I replace the rotor blades on my helicopter?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the fuel mixture ratio for my chainsaw?
[DEBUG] nova_text_handler called with mode=Auto, question=How do I adjust the derailleur on my bicycle?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the oil capacity for a Boeing 747?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How do I winterize my boat engine?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the tire pressure for a forklift?
[DEBUG] nova_text_handler called with mode=Auto, question=How do I maintain my riding lawnmower carburetor?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the hydraulic fluid spec for my tractor?
[DEBUG] nova_text_handler called with mode=Auto, question=How do I adjust the governor on my go-kart?
[DEBUG] nova_text_handler called with mode=Auto, question=What's the spark plug gap for my motorcycle?
[DEBUG] nova_text_handler called with mode=Auto, question=How do I teach my car to speak French?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=What's the emotional state of my alternator?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=Can I use peanut butter as engine oil?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How do I install feelings into my transmission?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=What's the zodiac sign of my battery?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
127.0.0.1 - - [30/Dec/2025 11:07:20] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:08:11] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:08:51] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:09:31] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:10:13] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:10:56] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:11:33] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:12:11] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:12:59] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:13:19] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:13:53] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:14:49] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:15:29] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:16:10] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:16:41] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:17:22] "POST /api/ask HTTP/1.1" 200 -
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=Can I charge my phone by connecting it to the spark plugs?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How do I make my engine sentient?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=What's the IQ of my radiator?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=Can I use maple syrup instead of brake fluid?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How do I perform CPR on my fuel pump?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 65.83%
[DEBUG-BACKEND] Individual confidences: [0.9500000476837158, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How much oil does it need?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=What's the torque spec?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 65.83%
[DEBUG-BACKEND] Individual confidences: [0.9500000476837158, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How often should I change it?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 65.83%
[DEBUG-BACKEND] Individual confidences: [0.9500000476837158, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=Is this normal?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=What should the pressure be?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 66.30%
[DEBUG-BACKEND] Individual confidences: [0.9500000476837158, 0.6279273629188538, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How do I reset it?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=What's the gap supposed to be?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How tight should it be?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 65.83%
[DEBUG-BACKEND] Individual confidences: [0.9500000476837158, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=What's the capacity?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How long does it take?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 65.83%
[DEBUG-BACKEND] Individual confidences: [0.9500000476837158, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=It's making a noise, what's wrong?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
127.0.0.1 - - [30/Dec/2025 11:18:25] "POST /api/ask HTTP/1.1" 200 -
[NIC-REFINE] Max refinement loops (2) reached with confidence 0.50
127.0.0.1 - - [30/Dec/2025 11:19:42] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:20:13] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:20:59] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:21:39] "POST /api/ask HTTP/1.1" 200 -
[NIC-AUDIT] Answer rejected: No valid citations found in strict mode
127.0.0.1 - - [30/Dec/2025 11:22:20] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:22:41] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:23:28] "POST /api/ask HTTP/1.1" 200 -
[NIC-AUDIT] Answer rejected: No valid citations found in strict mode
127.0.0.1 - - [30/Dec/2025 11:24:08] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:24:55] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:24:58] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:25:01] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:25:04] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:25:07] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:25:10] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:25:14] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:25:17] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:25:20] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:25:23] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:25:25] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:25:28] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:25:31] "POST /api/ask HTTP/1.1" 200 -
[NIC-REFINE] Max refinement loops (2) reached with confidence 0.50
127.0.0.1 - - [30/Dec/2025 11:26:22] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:24] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:27] "POST /api/ask HTTP/1.1" 200 -
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=They said I need to replace this, is that right?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=This thing is leaking, what should I do?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 65.83%
[DEBUG-BACKEND] Individual confidences: [0.9500000476837158, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=He told me it's bad, should I fix it?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=That part looks worn, do I need a new one?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=Someone said this is the problem, are they right?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: openai/gpt-oss-20b
[NovaRAG]  Using requested model: openai/gpt-oss-20b
[DEBUG] nova_text_handler called with mode=Auto, question=The guy mentioned something about these, what are they?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=She recommended changing those, is that necessary?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=This feels loose, is that a problem?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: openai/gpt-oss-20b
[NovaRAG]  Using requested model: openai/gpt-oss-20b
[DEBUG] nova_text_handler called with mode=Auto, question=That looks dirty, should I clean it?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 77.50%
[DEBUG-BACKEND] Individual confidences: [0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869, 0.7750000357627869]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=How do I check the belt?
[DEBUG] Fast eval mode activated for: How do I check the belt?
[DEBUG] Retrieved 6 docs
[DEBUG] Fast eval returning answer (len=311)
[DEBUG] nova_text_handler called with mode=Auto, question=What's the procedure for bleeding?
[DEBUG] Fast eval mode activated for: What's the procedure for bleeding?
[DEBUG] Retrieved 6 docs
[DEBUG] Fast eval returning answer (len=310)
[DEBUG] nova_text_handler called with mode=Auto, question=How do I test the system?
[DEBUG] Fast eval mode activated for: How do I test the system?
[DEBUG] Retrieved 6 docs
[DEBUG] Fast eval returning answer (len=311)
[DEBUG] nova_text_handler called with mode=Auto, question=What's involved in a tune-up?
[DEBUG] Fast eval mode activated for: What's involved in a tune-up?
[DEBUG] Retrieved 6 docs
[DEBUG] Fast eval returning answer (len=310)
[DEBUG] nova_text_handler called with mode=Auto, question=How do I service it?
[DEBUG] Fast eval mode activated for: How do I service it?
[DEBUG] Retrieved 6 docs
[DEBUG] Fast eval returning answer (len=310)
[DEBUG] nova_text_handler called with mode=Auto, question=What's the replacement interval?
[DEBUG] Fast eval mode activated for: What's the replacement interval?
[DEBUG] Retrieved 6 docs
[DEBUG] Fast eval returning answer (len=310)
[DEBUG] nova_text_handler called with mode=Auto, question=How do I diagnose the problem?
[DEBUG] Fast eval mode activated for: How do I diagnose the problem?
[DEBUG] Retrieved 6 docs
[DEBUG] Fast eval returning answer (len=311)
[DEBUG] nova_text_handler called with mode=Auto, question=What's the maintenance schedule?
[DEBUG] Fast eval mode activated for: What's the maintenance schedule?
[DEBUG] Retrieved 6 docs
[DEBUG] Fast eval returning answer (len=311)
[DEBUG] nova_text_handler called with mode=Auto, question=How do I inspect for wear?
[DEBUG] Fast eval mode activated for: How do I inspect for wear?
[DEBUG] Retrieved 6 docs
[DEBUG] Fast eval returning answer (len=311)
[DEBUG] nova_text_handler called with mode=Auto, question=What are the symptoms of failure?
[DEBUG] nova_text_handler called with mode=Auto, question=Since alternators run on diesel, what grade should I use?
[DEBUG] nova_text_handler called with mode=Auto, question=My manual says to drain engine oil every 500 miles, is that right?
[DEBUG] nova_text_handler called with mode=Auto, question=I heard spark plugs need to be replaced every 1000 miles, correct?
[DEBUG-BACKEND] Passing 6 docs to agent with avg confidence 65.83%
[DEBUG-BACKEND] Individual confidences: [0.9500000476837158, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579]
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[NovaRAG]  Using requested model: fireball-meta-llama-3.2-8b-instruct-agent-003-128k-code-dpo
[DEBUG] nova_text_handler called with mode=Auto, question=Since brake fluid is flammable, should I keep it away from heat?
[DEBUG] nova_text_handler called with mode=Auto, question=My mechanic said to never check oil when engine is cold, right?
127.0.0.1 - - [30/Dec/2025 11:26:30] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:32] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:35] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:37] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:40] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:42] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:45] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:47] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:50] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:52] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:55] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:26:58] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:27:00] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:27:03] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:27:05] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:27:08] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:27:10] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:27:13] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:27:15] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:28:04] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:28:06] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:28:09] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:28:53] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:28:56] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:28:58] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:29:01] "POST /api/ask HTTP/1.1" 400 -
127.0.0.1 - - [30/Dec/2025 11:29:04] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:29:07] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:29:10] "POST /api/ask HTTP/1.1" 400 -
127.0.0.1 - - [30/Dec/2025 11:29:13] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:29:16] "POST /api/ask HTTP/1.1" 400 -
127.0.0.1 - - [30/Dec/2025 11:29:18] "POST /api/ask HTTP/1.1" 400 -
127.0.0.1 - - [30/Dec/2025 11:29:21] "POST /api/ask HTTP/1.1" 400 -
127.0.0.1 - - [30/Dec/2025 11:29:23] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:29:26] "POST /api/ask HTTP/1.1" 200 -
127.0.0.1 - - [30/Dec/2025 11:29:30] "POST /api/ask HTTP/1.1" 200 -
